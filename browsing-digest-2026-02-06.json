{
  "exportedAt": "2026-02-06T13:40:37.547Z",
  "date": "2026-02-06",
  "totalPages": 18,
  "pages": [
    {
      "url": "https://www.google.com/search?q=chrome+extension+that+track+dialy+browser+visits+time+reading+and+can+extract+website+content&sca_esv=71b86378781733a7&sxsrf=ANbL-n6Nl-ZWvvLLad5A5p-ud0FB4qch8w%3A1768813336334&ei=GPNtaaOTFL-4qtsPodCGqQk&ved=0ahUKEwij_9eUn5eSAxU_nGoFHSGoIZUQ4dUDCBE&uact=5&oq=chrome+extension+that+track+dialy+browser+visits+time+reading+and+can+extract+website+content&gs_lp=Egxnd3Mtd2l6LXNlcnAiXWNocm9tZSBleHRlbnNpb24gdGhhdCB0cmFjayBkaWFseSBicm93c2VyIHZpc2l0cyB0aW1lIHJlYWRpbmcgYW5kIGNhbiBleHRyYWN0IHdlYnNpdGUgY29udGVudEihXVChC1i_XHABeAGQAQCYAaAHoAHVRKoBBDYtMTG4AQPIAQD4AQGYAgGgAgPCAgoQABiwAxjWBBhHmAMA4gMFEgExIECIBgGQBgiSBwExoAfTHLIHALgHAMIHAzAuMcgHAoAIAA&sclient=gws-wiz-serp",
      "title": "chrome extension that track dialy browser visits time reading and can extract website content - Cerca con Google",
      "content": "Risultati di ricercaWebtime Tracker - Chrome Web StoreChrome Web Storehttps://chromewebstore.google.com ‚Ä∫ ...Chrome Web Storehttps://chromewebstore.google.com ‚Ä∫ ... ¬∑ Traduci questa paginaWebtime Tracker keeps track of how you spend time on the web and presents the stats in a useful and intuitive way.Mancanti: extract ‚Äé| Deve includere: extractAI OverviewAI Overview non √® disponibile per questa ricercaImpossibile generare un'overview dell'AI in questo momento. Riprova pi√π tardi. Several Chrome extensions track daily website visit times and allow for content extraction or data exporting. Top options include Webtime Tracker, Web Activity Time Tracker, and specialized tools like Web Tracker. These tools monitor active tab usage, generate reports, and allow extraction of text or links for productivity analysis.Webtime Tracker (Best for Detailed Analysis): Tracks time spent on individual websites, offers daily stats, exports to CSV, and includes screenshots.Web Activity Time Tracker (Best for Productivity): Monitors time, allows setting daily site limits, blocks sites, and provides detailed, visual analytics.Webtime Tracker is a free, ad-free extension that tracks your time spent on the web. It presents your stats in a useful way, inclu...Chrome Web StoreOverview. Web Tracker helps you track anything on the web. This extension helps you to track any texts that you are able to select...Chrome Web StoreWeb Activity Time Tracker is a Chrome extension that helps you monitor and optimize your online productivity. It can help you: * *Chrome Web Store#3 Webtime Tracker * The extension runs in the background and tracks the active Chrome window and tabs using a smart timer so it d...MemtimeLink Grabber is a Chrome extension that instantly extracts every link from any webpage. You can organize, filter, and export your ...link-grabber.comThe new version is available on the Chrome Store https://chromewebstore.google.com/detail/timespy-block-websites-po/ggomgkmpcnmfhg...GitHub5mYouTube¬∑Suresh SDET Automation6:23Clockify¬∑Clockify#1 Toggl Track: Productivity & Time Tracker The Toggl Track browser extension comes with one-click functionality. You can track ti...Memtime16 mar 2024 ‚Äî Overview. ... The \"Website Time Tracker\" Chrome extension helps you monitor and manage your time spent on different websites. It p...Chrome Web StoreWebtime Tracker - Chrome Web StoreWebtime Tracker is a free, ad-free extension that tracks your time spent on the web. It presents your stats in a useful way, inclu...Chrome Web StoreWeb TrackerOverview. Web Tracker helps you track anything on the web. This extension helps you to track any texts that you are able to select...Chrome Web StoreWeb Activity Time Tracker - Block Websites, Pomodoro & Web Analytics - Chrome Web StoreWeb Activity Time Tracker is a Chrome extension that helps you monitor and optimize your online productivity. It can help you: * *Chrome Web StoreHow to Track Time Spent on Websites? No-Effort Tools That ...#3 Webtime Tracker * The extension runs in the background and tracks the active Chrome window and tabs using a smart timer so it d...MemtimeLink Grabber ‚Äì Extract, Export & Manage URLs Effectively!Link Grabber is a Chrome extension that instantly extracts every link from any webpage. You can organize, filter, and export your ...link-grabber.comStigmatoz/web-activity-time-tracker: Chrome Extension that ...The new version is available on the Chrome Store https://chromewebstore.google.com/detail/timespy-block-websites-po/ggomgkmpcnmfhg...GitHubHow to Capture Page Load Time Using Simple Browser ...29 gen 2025 ‚Äî so this will take a lot of time and uh you will have to verify each and every link. so which is very tricky and which is time cons...YouTube¬∑Suresh SDET Automation5mFREE Chrome Time Tracking ExtensionCreate Clockify account. Sign up here for free. Install time tracking extension for Chrome. Get Clockify Time Tracker on the Chrom...Clockify¬∑Clockify6:23Are Time Tracking Extensions Worth It? Best Ones Reviewed#1 Toggl Track: Productivity & Time Tracker The Toggl Track browser extension comes with one-click functionality. You can track ti...MemtimeWebsite Time Tracker - Chrome Web Store16 mar 2024 ‚Äî Overview. ... The \"Website Time Tracker\" Chrome extension helps you monitor and manage your time spent on different websites. It p...Chrome Web Store Approfondisci in AI ModeLe risposte dell'AI potrebbero contenere errori. Scopri di pi√πGrazie Il tuo feedback aiuta Google a migliorare l'AI e altro ancora, anche quando l'impostazione Attivit√† web e app √® disattivata. Scopri di pi√π. Condividi altri feedbackSegnala un problemaChiudiFeedback positivoFeedback negativoGrazie Il tuo feedback aiuta Google a migliorare l'AI e altro ancora, anche quando l'impostazione Attivit√† web e app √® disattivata. Scopri di pi√π. Condividi altri feedbackSegnala un problemaChiudiMostra altro Il mio centro per gli annunci VideoYouTubeYouTube WebWork Time Tracker14 ott 2025Track Your Time Across Platforms with t... [truncated]",
      "timestamp": "2026-02-06T08:22:18.819Z",
      "domain": "www.google.com",
      "readingTime": 4
    },
    {
      "url": "https://www.google.com/search?q=ollama&oq=ollama&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORiABDIHCAEQABiABDIHCAIQABiABDIMCAMQABhDGIAEGIoFMgwIBBAAGEMYgAQYigUyBggFEEUYQTIGCAYQRRhBMgYIBxBFGEHSAQgyNjIyajBqOagCALACAQ&sourceid=chrome&ie=UTF-8",
      "title": "ollama - Cerca con Google",
      "content": "Risultati di ricercaRisultato web con link ai sitiOllamaOllamahttps://ollama.comOllamahttps://ollama.com ¬∑ Traduci questa paginaWhat will you build? ¬∑ Ollama is the easiest way to automate your work using open models, while keeping your data safe. ¬∑ Ollama works with your favorite tools ...Download OllamaDownload Ollama. macOS Linux Windows ¬∑ Download for ...LibraryOLMo 2 is a new family of 7B and 13B models trained on up to 5T ...Ollama SearchOlmo is a series of Open language models designed to enable the ...Ollama's documentationOllama is the easiest way to get up and running with large ...QuickstartThis quickstart will walk your through running your first model ...Altri risultati in ollama.com ¬ªLe persone hanno chiesto ancheA cosa serve l'Ollama?Ollama √® un framework open source progettato per la gestione e l'esecuzione dei Large Language Models: permette agli utenti di eseguire modelli AI localmente sui propri computer, offrendo un'API (Application Programming Interface) semplice per la creazione, l'esecuzione e la gestione di questi modelli.19 nov 2024Ollama, l'AI sbarca sul vostro PC - IlSoftware.itIlSoftware.ithttps://www.ilsoftware.it ‚Ä∫ focus ‚Ä∫ ollama-intelligenza-art...IlSoftware.ithttps://www.ilsoftware.it ‚Ä∫ focus ‚Ä∫ ollama-intelligenza-art...Come installare Ollama su Windows?0:054:55Clip suggerito ¬∑ 41 secondiOllama: Come eseguire un LLM in locale sul tuo PCYouTube¬∑Simone Rizzo¬∑26 set 2024YouTubeOllama: Come eseguire un LLM in locale sul tuo PC - YouTubeYouTubehttps://www.youtube.com ¬∑ Simone RizzoYouTubehttps://www.youtube.com ¬∑ Simone RizzoQuanto pesa Ollama?√à possibile utilizzare Ollama per eseguire TinyLlama eseguendo il comando qui sotto. Questo modello √® abbastanza leggero, quindi dovrebbe essere scaricato e avviato in tempi relativamente brevi, visto che pesa meno di 700 MB.8 lug 2024Progetto #25: Eseguire Ollama e vari LLM su Linux - Risposte InformaticheRisposte Informatichehttps://www.risposteinformatiche.it ‚Ä∫ eseguire-ollama-e-v...Risposte Informatichehttps://www.risposteinformatiche.it ‚Ä∫ eseguire-ollama-e-v...Come configurare Ollama?Vai alla scheda AI e fai clic sull'icona Impostazioni. Nella finestra Configurazione AI, fai clic su Modifica modelli AI e poi sul pulsante Aggiungi. Nella sezione Provider, scegli Ollama e vedrai http://localhost:11434 come parametro URL. Questo √® il localhost standard su cui verr√† eseguita l'API di Ollama.26 feb 2025Come connettere Ollama a ONLYOFFICE e usarloOnlyOfficehttps://www.onlyoffice.com ‚Ä∫ blog ‚Ä∫ 2025/02 ‚Ä∫ ollamaOnlyOfficehttps://www.onlyoffice.com ‚Ä∫ blog ‚Ä∫ 2025/02 ‚Ä∫ ollamaFeedbackVideoOllama Course ‚Äì Build AI Apps LocallyYouTube freeCodeCamp.org26 nov 202425 momenti chiave25 momenti chiave in questo videoOllama Course ‚Äì Build AI Apps LocallyYouTube¬∑freeCodeCamp.org¬∑26 nov 2024YouTubeIn questo video00:00Intro02:00What Is this course about?05:28Development Environment Setup06:43Ollama Deep Dive17:09Ollama Setup18:03Download Ollama Locally33:41LLM Parameters Deep Dive39:39Understanding Model Benchmarks47:09Pull in the Llava Multimodal MOdel and Captioning an Image - Hands-on52:13Summarize and Sentiment Analysis and Customizing Models with the Modelfile01:04:39Ollama REST API - Request JSON01:07:59Ollama Models Support Different Tasks - Summary01:10:42Ollama Model Running Under Msty App - Frontend Tool - RAG Hands-on01:24:14Interact with Llama3 in Python using Ollama REST API01:29:29Ollama Python Library Chatting with our Model01:37:15Using Ollama Show Function01:39:15Create a Custom Model in Code01:43:29Build a LLM App - Grocery List Organizer01:51:46Building RAG Systems with Ollama - Overview of RAG Systems and Langchain Crash Course02:05:33Overview of Our PDF RAG System We will be Building02:07:29Set up our RAG System - Document Ingestion and Vector DB Creation and Embeddings02:24:27RAG System - Cleaner Code (Code Refactoring)02:26:26RAG System - Streamlit Version02:28:33Introduction to the Next Application - AI Recruiter Agency02:56:13Outro - Final Thoughts and Your Bonus - Thank you!Learn Ollama in 15 Minutes - Run LLM Models Locally for FREEYouTube Tech With Tim13 gen 20258 momenti chiave8 momenti chiave in questo videoLearn Ollama in 15 Minutes - Run LLM Models Locally for FREEYouTube¬∑Tech With Tim¬∑13 gen 2025YouTubeIn questo video00:00Ollama Introduction00:37Installing Ollama01:33Running Models Locally05:37Adding Multiple Models06:43Ollama HTTP Server/API08:26Calling The HTTP API (Code)10:24Ollama Python Package11:19Customizing ModelsRun AI Models Locally with Ollama: Fast & Simple DeploymentYouTube IBM Technology3 apr 20256 momenti chiave6 momenti chiave in questo videoRun AI Models Locally with Ollama: Fast & Simple DeploymentYouTube¬∑IBM Technology¬∑3 apr 2025YouTubeIn questo video00:32What Value Does this Open-Source Project Provide to You01:06Install the Command Line01:28Downloading and Chatting with a Model Locally01:36The Olama Run Command02:58Model Catalog05:22Code AssistanceMostra tuttoollama/ollama: Get up and running with Kimi-K2.5, ... [truncated]",
      "timestamp": "2026-02-06T08:22:24.843Z",
      "domain": "www.google.com",
      "readingTime": 4
    },
    {
      "url": "https://ollama.com/search",
      "title": "Ollama",
      "content": "Popular Newest ‚áÖ Ollama Search for models on Ollama. Cloud Embedding Vision Tools Thinking Popular Newest qwen3-coder-next Qwen3-Coder-Next is a coding-focused language model from Alibaba's Qwen team, optimized for agentic coding workflows and local development. tools cloud 9,433 Pulls 4 Tags Updated 3 hours ago glm-ocr GLM-OCR is a multimodal OCR model for complex document understanding, built on the GLM-V encoder‚Äìdecoder architecture. vision tools 7,619 Pulls 3 Tags Updated 3 days ago translategemma A new collection of open translation models built on Gemma 3, helping people communicate across 55 languages. vision 4b 12b 27b 200.1K Pulls 13 Tags Updated 2 weeks ago glm-4.7-flash As the strongest model in the 30B class, GLM-4.7-Flash offers a new option for lightweight deployment that balances performance and efficiency. tools thinking 145.7K Pulls 4 Tags Updated 1 week ago kimi-k2.5 Kimi K2.5 is an open-source, native multimodal agentic model that seamlessly integrates vision and language understanding with advanced agentic capabilities, instant and thinking modes, as well as conversational and agentic paradigms. cloud 35.7K Pulls 1 Tag Updated 1 week ago lfm2.5-thinking LFM2.5 is a new family of hybrid models designed for on-device deployment. tools 1.2b 38K Pulls 5 Tags Updated 2 weeks ago qwen3-vl The most powerful vision-language model in the Qwen model family to date. vision tools thinking cloud 2b 4b 8b 30b 32b 235b 1.4M Pulls 59 Tags Updated 3 months ago ministral-3 The Ministral 3 family is designed for edge deployment, capable of running on a wide range of hardware. vision tools cloud 3b 8b 14b 372.7K Pulls 16 Tags Updated 1 month ago rnj-1 Rnj-1 is a family of 8B parameter open-weight, dense models trained from scratch by Essential AI, optimized for code and STEM with capabilities on par with SOTA open-weight models. tools cloud 8b 306.9K Pulls 6 Tags Updated 1 month ago qwen3-next The first installment in the Qwen3-Next series with strong performance in terms of both parameter efficiency and inference speed. tools thinking cloud 80b 306.2K Pulls 10 Tags Updated 1 month ago granite4 Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications. tools 350m 1b 3b 653.6K Pulls 17 Tags Updated 3 months ago qwen3-embedding Building upon the foundational models of the Qwen3 series, Qwen3 Embedding provides a comprehensive range of text embeddings models in various sizes embedding 0.6b 4b 8b 566.4K Pulls 12 Tags Updated 4 months ago nemotron-3-nano Nemotron 3 Nano - A new Standard for Efficient, Open, and Intelligent Agentic Models tools thinking cloud 30b 148.6K Pulls 6 Tags Updated 1 month ago embeddinggemma EmbeddingGemma is a 300M parameter embedding model from Google. embedding 300m 480.8K Pulls 5 Tags Updated 5 months ago devstral-small-2 24B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents. vision tools cloud 24b 130.4K Pulls 6 Tags Updated 1 month ago olmo-3 Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets. 7b 32b 123.2K Pulls 15 Tags Updated 1 month ago deepseek-ocr DeepSeek-OCR is a vision-language model that can perform token-efficient OCR. vision 3b 152.5K Pulls 3 Tags Updated 2 months ago deepseek-v3.1 DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode. tools thinking cloud 671b 336.4K Pulls 8 Tags Updated 4 months ago olmo-3.1 Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets. tools 32b 73K Pulls 10 Tags Updated 1 month ago gemini-3-pro-preview Google's most intelligent model with SOTA reasoning and multimodal understanding, and powerful agentic and vibe coding capabilities. cloud 98K Pulls 1 Tag Updated 2 months ago",
      "timestamp": "2026-02-06T08:49:05.857Z",
      "domain": "ollama.com",
      "readingTime": 4
    },
    {
      "url": "https://ollama.com/library/qwen2.5",
      "title": "qwen2.5",
      "content": "qwen2.5 20.4M Downloads Updated 1 year ago Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support. Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support. Cancel tools 0.5b 1.5b 3b 7b 14b 32b 72b CLI cURL Python JavaScript Documentation Documentation ollama run qwen2.5 curl http://localhost:11434/api/chat \\ -d '{ \"model\": \"qwen2.5\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}] }' from ollama import chat response = chat( model='qwen2.5', messages=[{'role': 'user', 'content': 'Hello!'}], ) print(response.message.content) import ollama from 'ollama' const response = await ollama.chat({ model: 'qwen2.5', messages: [{role: 'user', content: 'Hello!'}], }) console.log(response.message.content) Applications Claude Code ollama launch claude --model qwen2.5 Codex ollama launch codex --model qwen2.5 OpenCode ollama launch opencode --model qwen2.5 OpenClaw ollama launch openclaw --model qwen2.5 Models View all ‚Üí Name 133 models Size Context Input qwen2.5:latest 4.7GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:latest 4.7GB 32K Text qwen2.5:0.5b 398MB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:0.5b 398MB 32K Text qwen2.5:1.5b 986MB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:1.5b 986MB 32K Text qwen2.5:3b 1.9GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:3b 1.9GB 32K Text qwen2.5:7b latest 4.7GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:7b latest 4.7GB 32K Text qwen2.5:14b 9.0GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:14b 9.0GB 32K Text qwen2.5:32b 20GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:32b 20GB 32K Text qwen2.5:72b 47GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:72b 47GB 32K Text Readme Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, a range of base language models and instruction-tuned models are released, with sizes ranging from 0.5 to 72 billion parameters. Qwen2.5 introduces the following improvements over Qwen2: It possesses significantly more knowledge and has greatly enhanced capabilities in coding and mathematics, due to specialized expert models in these domains. It demonstrates significant advancements in instruction following, long-text generation (over 8K tokens), understanding structured data (e.g., tables), and generating structured outputs, especially in JSON format. It is also more resilient to diverse system prompts, improving role-play and condition-setting for chatbots. It supports long contexts of up to 128K tokens and can generate up to 8K tokens. It offers multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. Please note: all models except the 3B and 72B are released under the Apache 2.0 license, while the 3B and 72B models are under the Qwen license. References GitHub Blog post HuggingFace <img src=\"https://ollama.com/assets/library/qwen2.5/4b4f719f-c327-489e-8dc1-89a455c21e89\" width=\"320\" /> Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, a range of base language models and instruction-tuned models are released, with sizes ranging from 0.5 to 72 billion parameters. Qwen2.5 introduces the following improvements over Qwen2: - It possesses **significantly more knowledge** and has greatly enhanced capabilities in **coding** and **mathematics**, due to specialized expert models in these domains. - It demonstrates significant advancements in **instruction following**, **long-text generation** (over 8K tokens), **understanding structured data** (e.g., tables), and **generating structured outputs**, especially in JSON format. It is also **more resilient to diverse system prompts**, improving role-play and condition-setting for chatbots. - It supports **long contexts** of up to 128K tokens and can generate up to 8K tokens. - It offers **multilingual support** for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. Please note: all models except the 3B and 72B are released under the Apache 2.0 license, while the 3B and 72B models are under the Qwen license. ## References [GitHub](https://github.com/QwenLM/Qwen2.5) [Blog post](https://qwenlm.github.io/blog/qwen2.5/) [HuggingFace](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e) Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif)",
      "timestamp": "2026-02-06T08:49:30.075Z",
      "domain": "ollama.com",
      "readingTime": 4
    },
    {
      "url": "https://ollama.com/search?q=lfm2",
      "title": "lfm2 ¬∑ Ollama",
      "content": "Popular Newest ‚áÖ lfm2 ¬∑ Ollama Search for models on Ollama. Cloud Embedding Vision Tools Thinking Popular Newest lfm2.5-thinking LFM2.5 is a new family of hybrid models designed for on-device deployment. tools 1.2b 38K Pulls 5 Tags Updated 2 weeks ago nn-tsuzu/lfm2.5-1.2b-instruct 11 Pulls 1 Tag Updated yesterday huihui_ai/lfm2.5-abliterated LFM2.5 is a new family of hybrid models designed for on-device deployment. tools 1.2b 649 Pulls 10 Tags Updated 1 week ago tomng/lfm2.5-instruct LFM2.5 is a new family of hybrid models designed for on-device deployment. tools 1.2b 236 Pulls 5 Tags Updated 2 weeks ago sam860/lfm2.5 An upgraded version of LFM2 trained on over twice as many tokens 1,592 Pulls 2 Tags Updated 1 month ago kahnwong/lfm2 92 Pulls 1 Tag Updated 3 months ago jewelzufo/medical-assistant-350m Optimized assistant based on: mkurman/lfm2-350M-med. Note: This model is experimental and not meant for medical advice. 15 Pulls 1 Tag Updated 2 months ago jewelzufo/lfm2-700-gguf 2 Pulls 1 Tag Updated 1 week ago yasserrmd/GLM4.7-Distill-LFM2.5-1.2B 27 Pulls 1 Tag Updated 2 days ago esquerbatua/LFM2.5-1.2B-Instruct-F16 1 Pull 1 Tag Updated 15 hours ago hadad/LFM2.5-1.2B LFM2.5 is a new family of hybrid models designed for on-device deployment. It builds on the LFM2 architecture with extended pre-training and reinforcement learning. 393 Pulls 4 Tags Updated 2 weeks ago sam860/LFM2 Small models made to run on mobile devices, developed by Liquid AI 350m 700m 1.2b 2.6b 8b 4,514 Pulls 19 Tags Updated 1 month ago cnmoro/LFM2-2.6B tools 498 Pulls 1 Tag Updated 4 months ago cnmoro/LFM2-350M-PTBR tools 62 Pulls 2 Tags Updated 4 months ago Wylgrif/LFM2-2.6B-Exp-Fr LFM2-2.6B finetuned on a french dataset to to strengthen his French language skills. If it doesn't work, update your ollama app. 30 Pulls 1 Tag Updated 1 month ago mistral-large Mistral Large 2 is Mistral's new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages. tools 123b 484.9K Pulls 32 Tags Updated 1 year ago saicharan1010/SmolLM2-FT-legal-india This is a fine-tuned version of the SmolLM2-135M-Instruct model, trained on legal texts from the Indian-Law dataset by vishnun0027 on Hugging Face. 79 Pulls 1 Tag Updated 11 months ago goliath A language model created by combining two fine-tuned Llama 2 70B models into one. 150.9K Pulls 16 Tags Updated 2 years ago jace-ai/SmolLM2-German-Instruct Extensively pre-trained and instruction fine-tuned version of SmolLM2 360M, now supercharged with German language capabilities! 360m 358 Pulls 4 Tags Updated 6 months ago microai/calm2-7b-chat CyberAgentLM2-Chat is a fine-tuned model of CyberAgentLM2 for dialogue use cases. 271 Pulls 1 Tag Updated 1 year ago",
      "timestamp": "2026-02-06T08:50:14.511Z",
      "domain": "ollama.com",
      "readingTime": 3
    },
    {
      "url": "https://ollama.com/library/qwen2.5",
      "title": "qwen2.5",
      "content": "qwen2.5 20.4M Downloads Updated 1 year ago Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support. Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support. Cancel tools 0.5b 1.5b 3b 7b 14b 32b 72b CLI cURL Python JavaScript Documentation Documentation ollama run qwen2.5 curl http://localhost:11434/api/chat \\ -d '{ \"model\": \"qwen2.5\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}] }' from ollama import chat response = chat( model='qwen2.5', messages=[{'role': 'user', 'content': 'Hello!'}], ) print(response.message.content) import ollama from 'ollama' const response = await ollama.chat({ model: 'qwen2.5', messages: [{role: 'user', content: 'Hello!'}], }) console.log(response.message.content) Applications Claude Code ollama launch claude --model qwen2.5 Codex ollama launch codex --model qwen2.5 OpenCode ollama launch opencode --model qwen2.5 OpenClaw ollama launch openclaw --model qwen2.5 Models View all ‚Üí Name 133 models Size Context Input qwen2.5:latest 4.7GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:latest 4.7GB 32K Text qwen2.5:0.5b 398MB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:0.5b 398MB 32K Text qwen2.5:1.5b 986MB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:1.5b 986MB 32K Text qwen2.5:3b 1.9GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:3b 1.9GB 32K Text qwen2.5:7b latest 4.7GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:7b latest 4.7GB 32K Text qwen2.5:14b 9.0GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:14b 9.0GB 32K Text qwen2.5:32b 20GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:32b 20GB 32K Text qwen2.5:72b 47GB ¬∑ 32K context window ¬∑ Text ¬∑ 1 year ago qwen2.5:72b 47GB 32K Text Readme Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, a range of base language models and instruction-tuned models are released, with sizes ranging from 0.5 to 72 billion parameters. Qwen2.5 introduces the following improvements over Qwen2: It possesses significantly more knowledge and has greatly enhanced capabilities in coding and mathematics, due to specialized expert models in these domains. It demonstrates significant advancements in instruction following, long-text generation (over 8K tokens), understanding structured data (e.g., tables), and generating structured outputs, especially in JSON format. It is also more resilient to diverse system prompts, improving role-play and condition-setting for chatbots. It supports long contexts of up to 128K tokens and can generate up to 8K tokens. It offers multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. Please note: all models except the 3B and 72B are released under the Apache 2.0 license, while the 3B and 72B models are under the Qwen license. References GitHub Blog post HuggingFace <img src=\"https://ollama.com/assets/library/qwen2.5/4b4f719f-c327-489e-8dc1-89a455c21e89\" width=\"320\" /> Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, a range of base language models and instruction-tuned models are released, with sizes ranging from 0.5 to 72 billion parameters. Qwen2.5 introduces the following improvements over Qwen2: - It possesses **significantly more knowledge** and has greatly enhanced capabilities in **coding** and **mathematics**, due to specialized expert models in these domains. - It demonstrates significant advancements in **instruction following**, **long-text generation** (over 8K tokens), **understanding structured data** (e.g., tables), and **generating structured outputs**, especially in JSON format. It is also **more resilient to diverse system prompts**, improving role-play and condition-setting for chatbots. - It supports **long contexts** of up to 128K tokens and can generate up to 8K tokens. - It offers **multilingual support** for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. Please note: all models except the 3B and 72B are released under the Apache 2.0 license, while the 3B and 72B models are under the Qwen license. ## References [GitHub](https://github.com/QwenLM/Qwen2.5) [Blog post](https://qwenlm.github.io/blog/qwen2.5/) [HuggingFace](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e) Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif)",
      "timestamp": "2026-02-06T08:52:24.419Z",
      "domain": "ollama.com",
      "readingTime": 4
    },
    {
      "url": "https://github.com/ollama/ollama/issues/3575",
      "title": "Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted. ¬∑ Issue #3575 ¬∑ ollama/ollama",
      "content": "Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted. #3575New issueNew issueClosedClosedError: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.#3575LabelsbugSomething isn't workingDescriptionCoder-Vishaliopened on Apr 10, 2024What is the issue? When I execute ollama serve, I face the below issue: Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted. ** ** Things which I have tired out: Restarted my machine Stop and start the ollama server Kill the port using: netstat -ano | findstr :, taskkill /PID /F What did you expect to see? No response Steps to reproduce No response Are there any recent changes that introduced the issue? No response OS Windows Architecture x86 Platform No response Ollama version No response GPU No response GPU info No response CPU No response Other software No responseActivityCoder-Vishaliadded bugSomething isn't working needs-triage on Apr 10, 2024muxixi727 commented on Apr 11, 2024 muxixi727on Apr 11, 2024You can close ollama that is opened locallyüëçReact with üëç72üéâReact with üéâ9‚ù§Ô∏èReact with ‚ù§Ô∏è11Coder-Vishaliclosed this as completedon Apr 11, 20244G3NTR0LLC4G3 commented on Apr 19, 2024 4G3NTR0LLC4G3on Apr 19, 2024In order to close the \"local\" ollama go to the bottom right of taskbar on windows click the up arrow, and quit ollama from the small tiny ollama app icon in the small arrow key menu. SO CONFUSING> If you then go back and run ollama serve it should work now.üëçReact with üëç157üòÑReact with üòÑ12üéâReact with üéâ24‚ù§Ô∏èReact with ‚ù§Ô∏è37üöÄReact with üöÄ14üëÄReact with üëÄ5cumtsd commented on May 21, 2024 cumtsdon May 21, 2024i've got the same problem without solvedsmspgh commented on May 31, 2024 smspghon May 31, 2024 ¬∑ edited by smspghEditsThere are 2 processes that are effectively activated when running Ollama Client in windows. You will find ollama and ollama app. The one is the parent controlling the localhost serving endpoint @ port 11434.. The other which is ollama app and if not killed will instantly restart the server on port 11434 if you only kill the one. So, if you kill both or at least kill \"ollama app\" process, it should take care of that issue. Here is your shortcut: Get-Process ollama* | Stop-Process -Force | ollama serveüëçReact with üëç15Shoaib5136 commented on Jun 10, 2024 Shoaib5136on Jun 10, 2024 You can close ollama that is opened locally Thanks, dude I was also searching for this many hours.YuChenXin-ZJU commented on Jul 28, 2024 YuChenXin-ZJUon Jul 28, 2024Are there any other ports I can call?smspgh commented on Jul 28, 2024 smspghon Jul 28, 2024@YuChenXin-ZJU If you mean can you set a port that is different to call then yes.. You would use: setx OLLAMA_HOST \"127.0.0.1:YOUR_DESIRED_PORT\" /M then just restart ollama.PrithivJith commented on Jul 30, 2024 PrithivJithon Jul 30, 2024Hello, I had this same issue a simple computer restart fixed this for me. Hope this helped :DEagleEye2010 commented on Sep 28, 2024 EagleEye2010on Sep 28, 2024 In order to close the \"local\" ollama go to the bottom right of taskbar on windows click the up arrow, and quit ollama from the small tiny ollama app icon in the small arrow key menu. SO CONFUSING> If you then go back and run ollama serve it should work now. Saving my insanity.hakeemsalman commented on Jan 22, 2025 hakeemsalmanon Jan 22, 2025 In order to close the \"local\" ollama go to the bottom right of taskbar on windows click the up arrow, and quit ollama from the small tiny ollama app icon in the small arrow key menu. SO CONFUSING> If you then go back and run ollama serve it should work now. It's SOLVED, thank you so much.ESTAS-crypto commented on Jan 31, 2025 ESTAS-cryptoon Jan 31, 2025I also have almost the same problem Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.meqasim commented on Feb 3, 2025 meqasimon Feb 3, 2025 You can close ollama that is opened locally It work. Sometime solution is infront of us, but we are searching somewhere elsemanav-a-thinkwik commented on Feb 12, 2025 manav-a-thinkwikon Feb 12, 2025 In order to close the \"local\" ollama go to the bottom right of taskbar on windows click the up arrow, and quit ollama from the small tiny ollama app icon in the small arrow key menu. SO CONFUSING> If you then go back and run ollama serve it should work now. thanks brother In order to close the \"local\" ollama go to the bottom right of taskbar on windows click the up arrow, and quit ollama from the small tiny ollama app icon in the small arrow key menu. SO CONFUSING> If you then go back and run ollama serve it should work now. thanks brotherTechnorocker commented on May 25, 2025 Technorockeron May 25, 2025what about when there is no local ollama running and Im trying to setup ollama as a service but the on... [truncated]",
      "timestamp": "2026-02-06T09:14:47.355Z",
      "domain": "github.com",
      "readingTime": 5
    },
    {
      "url": "https://www.google.com/search?q=force+itf-8+windows+terminal&oq=force+itf-8+windows+terminal&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRifBdIBCDk0MzRqMGo0qAIAsAIB&sourceid=chrome&ie=UTF-8",
      "title": "force itf-8 windows terminal - Cerca con Google",
      "content": "Using UTF-8 Encoding (CHCP 65001) in Command ...Stack Overflow4 risposte ¬∑ 6 anni faStack Overflow4 risposte ¬∑ 6 anni faTo activate it: Control Panel > Region > Administrative. This sets both the system's active OEM and the ANSI code page to 65001, the UTF-8 code page.4 risposte ¬∑ Miglior risposta: Note: This answer shows how to switch ...How to display utf-8 in windows console - Stack Overflow4 risposte26 ago 2010Windows 10 CLI UTF-8 encoding - Stack Overflow2 risposte27 feb 2018Altri risultati in stackoverflow.comChange default code page of Windows console to UTF-8Super Userhttps://superuser.com ‚Ä∫ questionsSuper Userhttps://superuser.com ‚Ä∫ questions ¬∑ Traduci questa pagina12 apr 2011 ‚Äî To change the codepage for the console only, do the following: Start -> Run -> regedit; Go to [HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Command ...9 risposte ¬∑ Miglior risposta: To change the codepage for the console only, do the following: Start -> Run -> regedit ...UTF8 characters in windows 10 bash terminal - Super User4 risposte3 ago 2016Converting text file to UTF-8 on Windows command ...7 risposte5 gen 2017Altri risultati in superuser.comHow to set UTF-8 in Windows Terminal ¬∑ Issue #11956GitHubhttps://github.com ‚Ä∫ issuesGitHubhttps://github.com ‚Ä∫ issues ¬∑ Traduci questa pagina15 dic 2021 ‚Äî The current solution is to turn on utf-8 in the language set by the system. This does work, but some old applications may not support utf8, so there will be ...UTF-8 console input now works in Windows Terminal.Reddit ¬∑ r/cpp_questions3 commenti ¬∑ 1 anno faReddit ¬∑ r/cpp_questions3 commenti ¬∑ 1 anno faI discovered just now that UTF-8 console input now works in Windows Terminal. I will have to update my how-to about UTF-8 in C++ in Windows.3 risposte ¬∑ Miglior risposta: Oh I don't know if it's yet the default. I don't think it is. But maybe.Does Windows 11 terminal defaults to UTF-8 ? : r ...5 risposte6 lug 2021Using UTF-8 in the Windows Terminal : r/commandline ...2 risposte22 gen 2020Altri risultati in www.reddit.comWindows Command prompt displays UTF-8 tamil ...Microsoft Learnhttps://learn.microsoft.com ‚Ä∫ wi...Microsoft Learnhttps://learn.microsoft.com ‚Ä∫ wi... ¬∑ Traduci questa pagina7 apr 2023 ‚Äî Go to the language settings; Click Administrative language settings; Change system locale‚Ä¶ and tick the Beta: Use Unicode UTF-8 for worldwide ...5 risposte ¬∑ Miglior risposta: Hello! My name is Mostafa, and I‚Äôm an independent advisor and a long-time Microsoft user. ...Solved: UTF-8 for windows CMDExperts Exchangehttps://www.experts-exchange.com ‚Ä∫ ...Experts Exchangehttps://www.experts-exchange.com ‚Ä∫ ... ¬∑ Traduci questa pagina1 feb 2011 ‚Äî Setting unicode for cmd would be typing chcp 65000 for UTF-8 Unicode. You may also try 950 for Traditional Chinese or 936 for Simplified ...Using UTF-8 in the Windows Terminal | seize the devakr.amhttps://akr.am ‚Ä∫ blog ‚Ä∫ posts ‚Ä∫ u...akr.amhttps://akr.am ‚Ä∫ blog ‚Ä∫ posts ‚Ä∫ u... ¬∑ Traduci questa pagina22 gen 2020 ‚Äî Enable the new UTF-8 option in Windows settings. Go to the language settings, click Administrative language settings, then Change system locale‚Ä¶How to solve the problem of garbled characters when ...Tencent Cloudhttps://www.tencentcloud.com ‚Ä∫ ...Tencent Cloudhttps://www.tencentcloud.com ‚Ä∫ ... ¬∑ Traduci questa pagina22 mag 2025 ‚Äî Instead of cmd, use tools like Windows Terminal with PowerShell or third-party SSH clients (e.g., MobaXterm, PuTTY) that support encoding ...Le persone hanno chiesto ancheHow do I enable UTF-8 in Windows Terminal?Enable the new UTF-8 option in Windows settings. Go to the language settings, click Administrative language settings, then Change system locale‚Ä¶ and tick the Beta: Use Unicode UTF-8 for worldwide language support option. Restart your computer.22 gen 2020Using UTF-8 in the Windows Terminal | seize the dev - akr.amakr.amhttps://akr.am ‚Ä∫ blog ‚Ä∫ posts ‚Ä∫ using-utf-8-in-the-windo...akr.amhttps://akr.am ‚Ä∫ blog ‚Ä∫ posts ‚Ä∫ using-utf-8-in-the-windo...How do I force UTF-8 encoding in Windows?Set a process code page to UTF-8 To configure your app to render UTF-8 text via GDI, go to Windows Settings > Time & language > Language & region > Administrative language settings > Change system locale, and check Beta: Use Unicode UTF-8 for worldwide language support. Then reboot the PC for the change to take effect.18 lug 2025Use UTF-8 code pages in Windows apps - Microsoft LearnMicrosoft Learnhttps://learn.microsoft.com ‚Ä∫ apps ‚Ä∫ design ‚Ä∫ globalizingMicrosoft Learnhttps://learn.microsoft.com ‚Ä∫ apps ‚Ä∫ design ‚Ä∫ globalizingWhat does chcp 65001 do?chcp 65001 sets both InputEncoding and OutputEncoding to UTF8.29 dic 2020What are the differences between chcp 65001 and [console]Microsoft Learnhttps://learn.microsoft.com ‚Ä∫ en-us ‚Ä∫ answers ‚Ä∫ questionsMicrosoft Learnhttps://learn.microsoft.com ‚Ä∫ en-us ‚Ä∫ answers ‚Ä∫ questionsIs Windows Terminal UTF-8?Windows Terminal can display Unicode and UTF-8 characters such as emoji and characters from a variety of languages.12 nov 2025An overview on Windows Termin... [truncated]",
      "timestamp": "2026-02-06T09:18:42.158Z",
      "domain": "www.google.com",
      "readingTime": 4
    },
    {
      "url": "https://www.google.com/search?q=UnicodeEncodeError%3A+%27charmap%27+codec+can%27t+encode+character+%27%5Cu200e%27+in+position+1057%3A+character+maps+to+%3Cundefined%3E&oq=UnicodeEncodeError%3A+%27charmap%27+codec+can%27t+encode+character+%27%5Cu200e%27+in+position+1057%3A+character+maps+to+%3Cundefined%3E&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg60gEHNDEyajBqN6gCALACAA&sourceid=chrome&ie=UTF-8",
      "title": "UnicodeEncodeError: 'charmap' codec can't encode character '\\u200e' in position 1057: character maps to <undefined> - Cerca con Google",
      "content": "Risultati di ricercapython - UnicodeEncodeError: 'charmap' codec can't encodeStack Overflow6 risposte ¬∑ 13 anni faStack Overflow6 risposte ¬∑ 13 anni faI see three solutions to this: Change the output encoding, so it will always output UTF-8. See e.g. Setting the correct encoding when piping ...6 risposte ¬∑ Miglior risposta: I see three solutions to this: Change the output encoding, so it will always output UTF-8. ...UnicodeEncodeError: 'charmap' codec can't encode ...13 risposte23 nov 2014Conda: UnicodeEncodeError: 'charmap' codec can't ...3 risposte29 gen 2020Altri risultati in stackoverflow.comMancanti: 1057: ‚Äé| Deve includere: 1057:'charmap' codec can't encode character '\\u200b'Reddit ¬∑ r/learnpythonOltre 10 commenti ¬∑ 8 anni faReddit ¬∑ r/learnpythonOltre 10 commenti ¬∑ 8 anni faYou can either use replace to remove the characters, or open your output file with encoding=\"utf-8\" to write them to the file. The ...Mancanti: u200e' ‚Äé1057:[BUG] UnicodeEncodeError: 'charmap' codec can't encode ...GitHubhttps://github.com ‚Ä∫ issuesGitHubhttps://github.com ‚Ä∫ issues ¬∑ Traduci questa pagina19 feb 2025 ‚Äî You need to force the encoding to \"utf-8\" by properly setting the required Python environment variable(s). You have more info in the Python docs.Mancanti: u200e' ‚Äé1057:Why I'm getting \"UnicodeEncodeError: 'charmap' codec can ...Stack Overflow3 risposte ¬∑ 5 anni faStack Overflow3 risposte ¬∑ 5 anni faWhy I'm getting \"UnicodeEncodeError: 'charmap' codec can't encode character '\\u25b2' in position 84811: character maps to <undefined>\" error?3 risposte ¬∑ Miglior risposta: There are hints in the full error message... I will keep here what seems most important: ...Mancanti: u200e' ‚Äé1057:UnicodeEncodeError: 'charmap' codec can't encode character ...Eclipse Capella Forumhttps://forum.mbse-capella.org ‚Ä∫ ...Eclipse Capella Forumhttps://forum.mbse-capella.org ‚Ä∫ ... ¬∑ Traduci questa pagina18 ott 2022 ‚Äî It seems like your Python is using the default encoding of your system: CP1252 (Windows). Not sure what the problem is here.Mancanti: u200e' ‚Äé1057:Charmap' codec can't encode characters in position 0-3Python.orghttps://discuss.python.org ‚Ä∫ ch...Python.orghttps://discuss.python.org ‚Ä∫ ch... ¬∑ Traduci questa paginaThis happens when the characters in some piece of text, which is being called input at this point, cannot be represented in the encoding that something has ...Mancanti: u200e' ‚Äé1057:'charmap' codec can't encode characters in position 0-1Google Groupshttps://groups.google.com ‚Ä∫ XH...Google Groupshttps://groups.google.com ‚Ä∫ XH... ¬∑ Traduci questa pagina'charmap' codec can't encode characters in position 0-1: character maps to <undefined> [3128] Failed to execute script gam if we do it without the \"> test\"Mancanti: u200e' ‚Äé1057:UnicodeEncodeError: 'charmap' codec can't encode ...JetBrainshttps://teamcity-support.jetbrains.com ‚Ä∫ ...JetBrainshttps://teamcity-support.jetbrains.com ‚Ä∫ ... ¬∑ Traduci questa pagina24 apr 2023 ‚Äî The error has been removed but getting the following error (UnicodeEncodeError: 'charmap' codec can't encode characters in position 337-402: character maps to ...Mancanti: u200e' ‚Äé1057:Le persone hanno chiesto ancheHow to fix Unicodeescape error in Python?0:011:18How to Fix SyntaxError: unicode error unicodeescape codec in Python ...YouTube¬∑Phil Parisi¬∑6 ott 2021YouTubeAnd run the file. No problem it opens up what I'm trying to do easily. The other solution is to addMoreAnd run the file. No problem it opens up what I'm trying to do easily. The other solution is to add double slashes. Between each of these. If I save this go ahead and run my file.How to Fix SyntaxError: unicode error unicodeescape codec in PythonYouTubehttps://www.youtube.com ¬∑ Phil ParisiYouTubehttps://www.youtube.com ¬∑ Phil ParisiWhat is Unicodeescape?Unicode escape sequences are used in program texts to represent Unicode characters. Such escape sequences are processed in identifiers, character and string literals. Escape sequences are not processed in any other program location. unicode-escape-sequence: \\u hex-digit hex-digit hex-digit hex-digit.Unicode Escape Sequencesfsight.ruhttps://help.fsight.ru ‚Ä∫ lexeme_unicode_escape_sequencefsight.ruhttps://help.fsight.ru ‚Ä∫ lexeme_unicode_escape_sequenceFeedbackUnicodeEncodeError: 'ascii' codec can't encode character ...GeeksforGeekshttps://www.geeksforgeeks.org ‚Ä∫ ...GeeksforGeekshttps://www.geeksforgeeks.org ‚Ä∫ ... ¬∑ Traduci questa pagina23 lug 2025 ‚Äî An error occurs when an attempt is made to save characters outside the range (or representable range) of an encoding scheme.'charmap' codec can't encode character '\\u200e' in position ...GitHubhttps://github.com ‚Ä∫ issuesGitHubhttps://github.com ‚Ä∫ issues ¬∑ Traduci questa pagina5 gen 2017 ‚Äî UnicodeEncodeError: 'charmap' codec can't encode character '\\u200e' in position 130: character maps to <undefined> (1 additional frame(s) ...Mancanti: 1057: ‚Äé| Deve includere: 1057:Le persone hanno chiesto ancheFeedbackRicerche correlateCharmap codec can t encode characte... [truncated]",
      "timestamp": "2026-02-06T09:22:38.501Z",
      "domain": "www.google.com",
      "readingTime": 4
    },
    {
      "url": "https://stackoverflow.com/questions/14630288/unicodeencodeerror-charmap-codec-cant-encode-character-maps-to-undefined",
      "title": "Just a moment...",
      "content": "stackoverflow.comVerifying you are human. This may take a few seconds.stackoverflow.com needs to review the security of your connection before proceeding.Verification successfulWaiting for stackoverflow.com to respond...",
      "timestamp": "2026-02-06T09:22:44.832Z",
      "domain": "stackoverflow.com",
      "readingTime": 1
    },
    {
      "url": "https://stackoverflow.com/questions/14630288/unicodeencodeerror-charmap-codec-cant-encode-character-maps-to-undefined",
      "title": "python - UnicodeEncodeError: 'charmap' codec can't encode - character maps to <undefined>, print function - Stack Overflow",
      "content": "This question shows research effort; it is useful and clear 191 Save this question. Show activity on this post. I am writing a Python 3.3 program to send some data to a webpage using POST method. Mostly for debugging process I am getting the page result and displaying it on the screen using print() function. The code is like this: conn.request(\"POST\", resource, params, headers) response = conn.getresponse() print(response.status, response.reason) data = response.read() print(data.decode('utf-8')); the HTTPResponse .read() method returns a bytes element encoding the page (which is a well formated UTF-8 document) It seemed okay until I stopped using IDLE GUI for Windows and used the Windows console instead. The returned page has a U+2014 character (em-dash) which the print function translates well in the Windows GUI (I presume Code Page 1252) but does not in the Windows Console (Code Page 850). Given the strict default behavior I get the following error: UnicodeEncodeError: 'charmap' codec can't encode character '\\u2014' in position 10248: character maps to <undefined> I could fix it using this quite ugly code: print(data.decode('utf-8').encode('cp850','replace').decode('cp850')) Now it replace the offending character \"‚Äî\" with a ?. Not the ideal case (a hyphen should be a better replacement) but good enough for my purpose. There are several things I do not like from my solution. The code is ugly with all that decoding, encoding, and decoding. It solves the problem for just this case. If I port the program for a system using some other encoding (latin-1, cp437, back to cp1252, etc.) it should recognize the target encoding. It does not. (for instance, when using again the IDLE GUI, the emdash is also lost, which didn't happen before) It would be nicer if the emdash translated to a hyphen instead of a interrogation bang. The problem is not the emdash (I can think of several ways to solve that particularly problem) but I need to write robust code. I am feeding the page with data from a database and that data can come back. I can anticipate many other conflicting cases: an '√Å' U+00c1 (which is possible in my database) could translate into CP-850 (DOS/Windows Console encodign for Western European Languages) but not into CP-437 (encoding for US English, which is default in many Windows instalations). Is there a nicer solution that makes my code agnostic from the output interface encoding? pythonencodingdecodeencode ShareShare a link to this question Copy linkCC BY-SA 4.0 Improve this question Follow Follow this question to receive notifications edited Aug 21, 2024 at 19:46 desertnaut 60.8k32 gold badges156 silver badges183 bronze badges asked Jan 31, 2013 at 16:18 Carlos Eugenio Thompson Pinz√≥n 2,6885 gold badges22 silver badges24 bronze badges 3 Add a comment | 6 Answers 6 Sorted by: Reset to default Highest score (default) Trending (recent votes count more) Date modified (newest first) Date created (oldest first) This answer is useful 117 Save this answer. Show activity on this post. I see three solutions to this: Change the output encoding, so it will always output UTF-8. See e.g. Setting the correct encoding when piping stdout in Python, but I could not get these example to work. Following example code makes the output aware of your target charset. # -*- coding: utf-8 -*- import sys print sys.stdout.encoding print u\"St√∂cker\".encode(sys.stdout.encoding, errors='replace') print u\"–°—Ç–æ–µ—Å–∫–µ—Ä\".encode(sys.stdout.encoding, errors='replace') This example properly replaces any non-printable character in my name with a question mark. If you create a custom print function, e.g. called myprint, using that mechanisms to encode output properly you can simply replace print with myprint whereever necessary without making the whole code look ugly. Reset the output encoding globally at the begin of the software: The page http://www.macfreek.nl/memory/Encoding_of_Python_stdout has a good summary what to do to change output encoding. Especially the section \"StreamWriter Wrapper around Stdout\" is interesting. Essentially it says to change the I/O encoding function like this: In Python 2: if sys.stdout.encoding != 'cp850': sys.stdout = codecs.getwriter('cp850')(sys.stdout, 'strict') if sys.stderr.encoding != 'cp850': sys.stderr = codecs.getwriter('cp850')(sys.stderr, 'strict') In Python 3: if sys.stdout.encoding != 'cp850': sys.stdout = codecs.getwriter('cp850')(sys.stdout.buffer, 'strict') if sys.stderr.encoding != 'cp850': sys.stderr = codecs.getwriter('cp850')(sys.stderr.buffer, 'strict') If used in CGI outputting HTML you can replace 'strict' by 'xmlcharrefreplace' to get HTML encoded tags for non-printable characters. Feel free to modify the approaches, setting different encodings, .... Note that it still wont work to output non-specified data. So any data, input, texts must be correctly convertable into unicode: # -*- coding: utf-8 -*- import sys import codecs sys.stdout = codecs.getwriter(\"iso-8859-1\")(sys.stdout, 'xmlcharrefre... [truncated]",
      "timestamp": "2026-02-06T09:23:12.023Z",
      "domain": "stackoverflow.com",
      "readingTime": 4
    },
    {
      "url": "https://ollama.com/library/llama3.2",
      "title": "llama3.2",
      "content": "llama3.2 55.8M Downloads Updated 1 year ago Meta's Llama 3.2 goes small with 1B and 3B models. Meta's Llama 3.2 goes small with 1B and 3B models. Cancel tools 1b 3b CLI cURL Python JavaScript Documentation Documentation ollama run llama3.2 curl http://localhost:11434/api/chat \\ -d '{ \"model\": \"llama3.2\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}] }' from ollama import chat response = chat( model='llama3.2', messages=[{'role': 'user', 'content': 'Hello!'}], ) print(response.message.content) import ollama from 'ollama' const response = await ollama.chat({ model: 'llama3.2', messages: [{role: 'user', content: 'Hello!'}], }) console.log(response.message.content) Applications Claude Code ollama launch claude --model llama3.2 Codex ollama launch codex --model llama3.2 OpenCode ollama launch opencode --model llama3.2 OpenClaw ollama launch openclaw --model llama3.2 Models View all ‚Üí Name 63 models Size Context Input llama3.2:latest 2.0GB ¬∑ 128K context window ¬∑ Text ¬∑ 1 year ago llama3.2:latest 2.0GB 128K Text llama3.2:1b 1.3GB ¬∑ 128K context window ¬∑ Text ¬∑ 1 year ago llama3.2:1b 1.3GB 128K Text llama3.2:3b latest 2.0GB ¬∑ 128K context window ¬∑ Text ¬∑ 1 year ago llama3.2:3b latest 2.0GB 128K Text Readme The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks. Sizes 3B parameters (default) The 3B model outperforms the Gemma 2 2.6B and Phi 3.5-mini models on tasks such as: Following instructions Summarization Prompt rewriting Tool use ollama run llama3.2 1B parameters The 1B model is competitive with other 1-3B parameter models. It‚Äôs use cases include: Personal information management Multilingual knowledge retrieval Rewriting tasks running locally on edge ollama run llama3.2:1b Benchmarks Supported Languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai are officially supported. Llama 3.2 has been trained on a broader collection of languages than these 8 supported languages. <img src=\"/assets/library/llama3.2/be01fadf-7fbd-404d-929b-50a77249b030\" width=\"280\" /> The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks. ## Sizes ### 3B parameters (default) The 3B model outperforms the Gemma 2 2.6B and Phi 3.5-mini models on tasks such as: * Following instructions * Summarization * Prompt rewriting * Tool use ``` ollama run llama3.2 ``` ### 1B parameters The 1B model is competitive with other 1-3B parameter models. It's use cases include: * Personal information management * Multilingual knowledge retrieval * Rewriting tasks running locally on edge ``` ollama run llama3.2:1b ``` ### Benchmarks ![Llama 3.2 instruction-tuned benchmarks](https://ollama.com/assets/library/llama3.2/c1a51716-d8bb-4642-8044-48f5022b777d) **Supported Languages:** English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai are officially supported. Llama 3.2 has been trained on a broader collection of languages than these 8 supported languages. Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif)",
      "timestamp": "2026-02-06T09:25:14.158Z",
      "domain": "ollama.com",
      "readingTime": 3
    },
    {
      "url": "https://medium.com/me/stats?publishedAt=DESC",
      "title": "Stories",
      "content": "SitemapOpen in appSidebar menuMedium LogoWriteSearchNotificationsSidebar menuMedium LogoHomeLibraryProfileStoriesStatsFollowingWrite A CatalystR. Thompson (PhD)ILLUMINATIONKennedy Selvadurai, PhDMark ThompsonDaniel Garc√≠aArtificial Intelligence in Plain EnglishAndrew BestAI AdvancesTowards AIMoreStatsStoriesAudiencePartner Program earningsMonthlyFebruary 1, 2026 ‚Äì Today (UTC)Updated hourlyFebruary 20262.8KPresentations808Views266Reads-1Followers0SubscribersFeb 1Feb 4Feb 7075150225ViewsReadsLifetimeMarch 25, 2023 ‚Äì Today (UTC)Updated dailyLatestStoryPresentationsViewsReadsEarningsRAG that works ‚Äî Mission #19 min readFeb 3, 2026View story1.3K11374$8.57Imagerouter.io: the free image generation API of January 20267 min readJan 29, 2026View story1.7K16797$5.73RAG that works: why chunking is a human job ‚Äî Mission #06 min readJan 27, 2026View story1.8K202116$9.01January 2026 AI discoveries9 min readJan 24, 2026View story2.2K254154$2.77Chocolatey for Python & AI enthusiasts: how to turn Windows into your in-house developer‚Ä¶9 min readJan 19, 2026View story2.6K330172$13.59Stop chasing AI benchmarks. Be the Benchmark.9 min readJan 15, 2026View story1.7K10042$3.17llama.CPP restyle is the workshop for your Local AI10 min readJan 2, 2026View story3.3K504298$27.30Excuse me? Llama.cpp + RWKV = Long context on cheap hardware8 min readDec 14, 2025View story3.3K558268$31.13Why write about Generative AI7 min readDec 13, 2025View story1.9K8942$3.26Don‚Äôt forget that programming is fun15 min readDec 9, 2025View story1.92K15759$1.28",
      "timestamp": "2026-02-06T09:25:51.802Z",
      "domain": "medium.com",
      "readingTime": 1
    },
    {
      "url": "https://www.whatsapp.com/",
      "title": "WhatsApp | Secure and Reliable Free Private Messaging and Calling",
      "content": "Skip to contentMessage privatelySimple, reliable, private messaging and calling for free*, available all over the world.DownloadLog inDownload* Data charges may apply. Contact your provider for details.With private messaging and calling, you can be yourself, speak freely and feel close to the most important people in your life no matter where they are.Never miss a moment with voice and video callsFrom a group call to classmates to a quick call with mom, feel like you‚Äôre in the same room with voice and video calls.Learn moreGet WhatsApp for WindowsChat and call on a larger screen with the desktop app.Download Windows appSpeakfreelyWith end-to-end encryption on WhatsApp, your personal messages and calls are secured with a lock. Only you and the person you're talking to can read or listen to them, and no one else, not even WhatsAppLearn moreKeep in touchwith your groupsWhether it's planning an outing with friends or simply staying on top of your family chats, group conversations should feel effortless.Learn moreSay whatyou feel Express yourself without words. Use stickers and GIFs or share everyday moments on Status. Record a voice message for a quick hello or a longer story.Learn moreTransformyour businessWhatsApp Business helps you reach your customers globally to deliver compelling experiences at scale. Showcase your products and services, increase sales, and build relationships all with WhatsApp.Learn more",
      "timestamp": "2026-02-06T12:26:54.395Z",
      "domain": "www.whatsapp.com",
      "readingTime": 2
    },
    {
      "url": "https://www.linkedin.com/feed/",
      "title": "Feed | LinkedIn",
      "content": "Fabio MatricardiControl System Engineer and AI solution strategist at Key Solution Srl Technical writer @Medium and @SubstackNovara, PiedmontKey Solution SrlUnlock monthly new benefits to advance your careerTry for ‚Ç¨0Profile viewers68Post impressions29Saved itemsGroupsNewslettersEventsStart a postVideoPhotoWrite articleSort by: TopNew postsFeed postAncil Joy reposted thisDmytro Kniaziev ‚Ä¢ 2ndSharing LNG knowledge from Gas Carriers.Visit my website3w ‚Ä¢ FollowHow FLNG Works? Step-by-Step Process:The #FLNG process integrates upstream extraction with downstream liquefaction and export, all offshore. 1Ô∏è‚É£ Natural gas is extracted from subsea wells on the ocean floor. It flows through pipelines or risers (flexible conduits) to the FLNG vessel moored above the field.2Ô∏è‚É£ Raw natural gas from wells or pipelines contains impurities that must be removed to prevent freezing, corrosion, or equipment damage during cooling:Acid Gas Removal - CO2 and H2S are extracted using chemical solvents (e.g., amine absorption) to avoid solidification or pipeline corrosion.Water is removed via molecular sieves or glycol dehydration to prevent ice formation.Heavy Hydrocarbon and Mercury Removal - Natural gas liquids (NGLs like ethane, propane) are separated by fractional distillation; mercury is filtered out. Dust, helium, and nitrogen may also be stripped if present.After pre-treatment, the gas is mostly methane (90-99%) at ambient temperature and high pressure.3Ô∏è‚É£ The purified gas is cooled in cryogenic heat exchangers using thermodynamic refrigeration cycles. Heat is removed progressively, condensing the gas into a liquid. Common methods include:*Cascade Process: Uses multiple refrigerants (e.g., propane, ethylene, methane) that boil at different temperatures in sequential cycles. Gas is cooled step-by-step, e.g., pre-cooled with propane to -35¬∞C, then ethylene to -100¬∞C, and methane to -162¬∞C.*Mixed Refrigerant (MR) Process: A single mixed refrigerant (iso-propane, iso-butane, ethane, nitrogen and methane) is used in a loop. It's efficient for large-scale plants in main cryogenic heat exchangers (MCHE). *Joule-Thomson valve (expansion cooling) takes the last step for cooling.4Ô∏è‚É£ LNG is stored in insulated cryogenic tanks on the vessel, maintaining the low temperature to keep it in liquid form. Byproducts like liquefied petroleum gas (LPG) or condensate are also separated and stored.5Ô∏è‚É£ Once tanks are full, LNG is transferred by STS or tandem off-loading to LNG carriers for delivery to global markets.Credit to TechnipFMC#PRO_LNG | #knowledge #liquefaction #naturalgasVideo Player is loading.Play VideoPauseSkip BackwardSkip ForwardUnmuteCurrent Time 0:00Duration 3:29Loaded: 0%Stream Type LIVESeek to live, currently behind liveRemaining Time 3:29 1xPlayback RateChaptersChaptersDescriptionsdescriptions off, selectedCaptionscaptions settings, opens captions settings dialogcaptions off, selectedAudio TrackPicture-in-PictureFullscreenYevgen Savarynyuk and 250 others reacted23 repostsLikeCommentRepostSendFeed postAndrea Pigozzo likes thisFortune ItaliaVisit website2h ‚Ä¢ Follow\"Le decisioni annunciate oggi riflettono in gran parte il prezzo di sopravvalutare il ritmo della transizione energetica che ci ha allontanato dalle esigenze, dai mezzi e dai desideri del mondo reale di molti acquirenti di auto\". Il Ceo di Stellantis Antonio Filosa riassume cos√¨ le cause di una manovra lacrime e sangue da 22,2 mld di euro.Stellantis ripulisce il bilancio dalle scelte del passato e mette nero su bianco i costi del suo riposizionamento sull‚Äôelettrico, e della svalutazione della strategia adottata finora. Intanto, crolla anche in Borsa quasi del 15%. üëâ Leggi l'articolo completo online al link https://lnkd.in/dAiJmYQyShow translationAndrea Pigozzo and 16 others reacted9 comments‚Ä¢1 repostLikeCommentRepostSendFeed postSuggestedMuhammad Sarim ‚Ä¢ 3rd+Intermediate CS Student at GDC | Data Engineering Aspirant | Developing Skills in SQL & Python1d ‚Ä¢ FollowDay 2 of Python üêç things finally started making sense Today I went a bit deeper into how Python actually handles data, and honestly‚Ä¶ it‚Äôs kinda cool how much it does for you. I learned that Python: Automatically figures out data types (no declarations, no stress) Lets you change a variable‚Äôs type anytime Handles memory quietly in the background while you just focus on logic I explored different data types like: int, float, str, bool None (which really means nothing, not even an empty string) And collections like lists, dictionaries, sets, and tuples One thing that really clicked today: functions vs methods print() and type() work on values .upper() and similar methods belong to specific data types And yes‚Ä¶ Python will complain if you try the wrong one üòÖ Big takeaway for me: everything in Python is an object, and each object only knows its own tricks. Slow progress, but solid foundations. One day at a time For those ahead of me what confused you the most when you first learned Python? üëÄ6 reactions1 commentLikeC... [truncated]",
      "timestamp": "2026-02-06T12:27:41.877Z",
      "domain": "www.linkedin.com",
      "readingTime": 4
    },
    {
      "url": "https://www.linkedin.com/in/fabio-matricardi-3292a939b/",
      "title": "Fabio Matricardi | LinkedIn",
      "content": "Fabio MatricardiControl System Engineer and AI solution strategist at Key Solution SrlTechnical writer @Medium and @SubstackEnhance profileAdd sectionOpen to Fabio (thePoorGPUguy) MatricardiHe/HimControl System Engineer and AI solution strategist at Key Solution SrlTechnical writer @Medium and @SubstackKey Solution Srl ¬∑ kaggleNovara, Piedmont, Italy¬∑Contact infoKey Solution Srlkaggle102 connectionsOpen toAdd sectionEnhance profileShow recruiters you‚Äôre open to work ‚Äî you control who sees this.Get startedShare that you‚Äôre hiring and attract qualified candidates.Get startedShowcase your services as a section on your profile so your business can be easily discovered.Add servicesTell non-profits you are interested in getting involved with your time and skillsGet startedSuggested for youPrivate to youWrite a summary to highlight your personality or work experienceMembers who include a summary receive up to 3.9 times as many profile views.Add a summaryAnalyticsPrivate to you68 profile viewsDiscover who‚Äôs viewed your profile.29 post impressionsCheck out who‚Äôs engaging with your posts.Past 7 days16 search appearancesSee how often you appear in search results.68 profile viewsDiscover who‚Äôs viewed your profile.29 post impressionsCheck out who‚Äôs engaging with your posts.Past 7 days16 search appearancesSee how often you appear in search results.Show allProfile languageEnglishPublic profile & URLwww.linkedin.com/in/fabio-matricardi-3292a939bWhy am I seeing this ad?Manage your ad preferencesHide or report this adI don‚Äôt want to see this ad in my feedTell us why you don‚Äôt want to see thisYour feedback will help us improve your experienceIt‚Äôs annoying or not interestingI‚Äôve seen the same ad too oftenIf you think this goes against our Professional Community Policies, please let us know.Report this adWho your viewers also viewedPrivate to youSomeone at Key Solution SrlViewProgram Administrator in the Oil and Gas industryViewSomeone at RWEViewSomeone at Key Solution SrlViewSomeone at Key Solution SrlViewYou might likePages for youUpstreamBook and Periodical Publishing70,254 followersPiter & 17 other connections follow this pageFollowSnam S.p.A.Utilities265,339 followersMohamed & 25 other connections follow this pageFollowShow allWhy am I seeing this ad?Manage your ad preferencesHide or report this adI don‚Äôt want to see this ad in my feedTell us why you don‚Äôt want to see thisYour feedback will help us improve your experienceIt‚Äôs annoying or not interestingI‚Äôve seen the same ad too oftenIf you think this goes against our Professional Community Policies, please let us know.Report this ad",
      "timestamp": "2026-02-06T12:27:53.458Z",
      "domain": "www.linkedin.com",
      "readingTime": 2
    },
    {
      "url": "https://blog.roboflow.com/what-is-yolo-world/",
      "title": "YOLO-World: Real-Time, Zero-Shot Object Detection",
      "content": "Blog YOLO-World: Real-Time, Zero-Shot Object Detection Piotr Skalski, James Gallagher Published Feb 13, 2024 ‚Ä¢ 6 min read On January 31st, 2024, Tencent‚Äôs AI Lab released YOLO-World (access code on Github), a real-time, open-vocabulary object detection model. YOLO-World is a zero-shot model, which means you can run object detection without any training.Follow our open source guide on how to use YOLO-World if you are interested in trying the model.üí°You can now try YOLO-World for free, no login required, with the Model Playground.YOLO-World was designed to solve a limitation of existing zero-shot object detection models: speed. Whereas other state-of-the-art models use Transformers, a powerful but typically slower architecture, YOLO-World uses the faster CNN-based YOLO architecture.Figure 1. Comparison of YOLO-World with the latest open vocabulary methods in terms of speed and accuracy. Models were compared on the LVIS dataset and measured on NVIDIA V100. Source YOLO-World paper.In this guide, we are going to discuss what YOLO-World is, the recent history of zero-shot object detection, and how the model performs according to the YOLO-World paper.Before we get started, check out the live demo below to see Yolo-World in action. From Fixed-Class Object Detectors to YOLO-WorldTraditional Object DetectorsTraditional object detection models, such as Faster R-CNN, SSD, and YOLO, are designed to identify objects within a predetermined set of categories defined by their training datasets. For instance, models trained on the COCO dataset are limited to 80 categories.This limitation restricts their applicability to scenarios that match the training data's scope. Extending or altering the set of recognizable classes necessitates retraining or fine-tuning the model on a custom dataset tailored to the new categories.Open-Vocabulary Object DetectionAs a response to the limitations of fixed-vocabulary detectors, open-vocabulary object detection (OVD) models aim to recognize objects beyond the predefined categories. Early attempts in this direction, such as GLIP and Grounding DINO, focused on leveraging large-scale image-text data to expand the training vocabulary, enabling the detection of novel objects. All you have to do is prompt the model and specify what objects you are looking for.Figure 2. GroundingDINO ‚Äúchair‚Äù vs ‚Äúdog's tail‚Äù prompt.However, they tend to be larger and more computationally intensive, requiring simultaneous encoding of images and texts for prediction. This approach, while powerful, introduces latency that can hinder practical applications. See this guide if you want to try GroundingDINO.What is YOLO-World?YOLO-World, introduced in the research paper ‚ÄúYOLO-World: Real-Time Open-Vocabulary Object Detection‚Äù, shows a significant advancement in the field of open-vocabulary object detection by demonstrating that lightweight detectors, such as those from the YOLO series, can achieve strong open-vocabulary performance. This is particularly noteworthy for real-world applications where efficiency and speed are crucial, like edge applications.YOLO World has grounding capabilities and can understand the context in a prompt to provide detections. You do not need to train the model on a particular class because the model has been trained using image-text pairs and grounded images. The model has learned how to take an arbitrary prompt ‚Äì for example, ‚Äúperson wearing a white shirt‚Äù ‚Äì and use that for detection.Figure 3. Comparison of different object detection inference paradigms. Source YOLO-World paper.YOLO-World introduces the \"prompt-then-detect\" paradigm, a novel approach that avoids the need for real-time text encoding. Instead, it allows for the generation of prompts by users, which are then encoded into an offline vocabulary.Figure 4. YOLO-World ‚Äúperson, backpack, dog, eye, nose, ear, tongue‚Äù prompt.By pre-encoding a series of user-generated prompts into an offline vocabulary, the model bypasses the need for real-time text encoding, enabling quicker and more adaptable detection.Unlike traditional methods, which rely on a fixed set of predefined categories, or earlier open-vocabulary approaches that encode user prompts in real-time (online vocabulary), YOLO-World introduces a more efficient alternative. This approach significantly reduces computational overhead [Figure 1.], allowing for dynamic adjustment of the detection vocabulary to meet varying needs without sacrificing performance, thus enhancing the model's utility in real-world applications.YOLO-World ArchitectureYOLO-World's architecture consists of three key elements:YOLO detector - based on Ultralytics YOLOv8; extracts the multi-scale features from the input image.Text Encoder - Transformer text encoder pre-trained by OpenAI‚Äôs CLIP; encodes the text into text embeddings.Re-parameterizable Vision-Language Path Aggregation Network (RepVL-PAN) - performs multi-level cross-modality fusion between image features and text embeddings.Figure 5. Overall Archi... [truncated]",
      "timestamp": "2026-02-06T12:33:33.576Z",
      "domain": "blog.roboflow.com",
      "readingTime": 4
    },
    {
      "url": "https://www.reddit.com/r/chrome_extensions/comments/194srj5/i_made_an_extension_that_lets_you_search_the/",
      "title": "I made an extension that lets you search the content of your tabs : r/chrome_extensions",
      "content": "Go to chrome_extensions r/chrome_extensions r/chrome_extensions Growing Learn, share, build, and discuss Chrome extensions in this awesome place. 40K Weekly visitors 1.2K Weekly contributions 2y ago MyViolets Portugu√™s (Brasil) I made an extension that lets you search the content of your tabs Right now I've got hundreds of open tabs, I cant even see the titles of them anymore. All I see is a long row of favicons and I only recognize about 10% of them. That's why I created Deep Tab Search, it lets you search the actual content of all those open tabs. It also doubles up as a pretty intuitive tab switcher since once you open the popup, all tabs are listed in the order of which you last viewed them. Try it here Link: https://chromewebstore.google.com/detail/dbppkkjmaloclihjakcpnionomlidbhk Share OpenAI ‚Ä¢ Promoted Codex is a coding agent from OpenAI. It handles everything from code reviews to bug triage so your developers can stay focused on solving what actually matters. Fully integrated with GitHub, Slack, and your existing toolchain, so no new setup required. Powered by ChatGPT, with paid plans. Sign Up chatgpt.com Best Open comment sort options Best Top New Controversial Old Q&A Possible-Scary 2y ago Edited 2y ago Nice extension! How‚Äôd you come up with the idea for it? Reply Share MyViolets 2y ago Thanks. Admittedly, it's not really an original idea since it's quite similar to Chrome's built-in tab search feature. I just never found Chrome's one that useful because it only filters by titles and urls. Deep Tab Search is essentially just my take on how I would like the built-in version to work. More replies rmfranco 2y ago \"However, Deep Tab Search will still work as expected with memory saver on, it just means that if it encounters any unloaded tabs, it will automatically reload them when you invoke the extension and show an \"Indexing tabs...\" message during this process.\" Question, does it reload all the tabs at once? Cause, I have multiple windows open for multiple things. My main youtube page, video game guides, my work-from-home youtube window, etc. I have an extension for the memory for this. I also have one that keeps count of how many tabs I've got open. As I type this, it says there are 752 atm. Most suspended. MyViolets 2y ago Thanks for the question. It does reload them all at once since it search tabs across all windows. What's your thoughts on it? Are you thinking the extension should search only the current window or that it should re-discard tabs that were discarded when it was opened? rmfranco 2y ago I don't really know, I didn't download the extension because I felt it wouldn't really be useful to me with how my other extension changes pages to a suspended page instead. siriusx03 5mo ago The tab should be indexed before it is suspended. If a tab is suspended, it shouldn't be unsuspended for indexing. When a tab is unsuspended by the user, then it should be indexed again. More replies More replies siriusx03 5mo ago alt+a doesn't do anything for me. Using Brave Browser on mac os sequoia. siriusx03 5mo ago Great extn! Thanks!",
      "timestamp": "2026-02-06T13:38:43.634Z",
      "domain": "www.reddit.com",
      "readingTime": 3
    }
  ]
}